{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0766c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy.special\n",
    "import dataclasses\n",
    "from functools import partial\n",
    "\n",
    "import vtk\n",
    "from vtk.util import numpy_support\n",
    "\n",
    "import jaxdem as jd\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a122385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# make rigid body particles\n",
    "# make spheres\n",
    "# make ellipsoids\n",
    "# make h5 io module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "698ccae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_spheres_vtp(filename, positions, radii, particle_ids=None):\n",
    "    \"\"\"\n",
    "    Writes particle positions, radii, and IDs to a .vtp file.\n",
    "    \n",
    "    Args:\n",
    "        filename (str): Output filename.\n",
    "        positions (array): (N, 2) or (N, 3) centers.\n",
    "        radii (array): (N,) radii.\n",
    "        particle_ids (array, optional): (N,) integer IDs for grouping/coloring.\n",
    "                                      If None, defaults to 0..N-1.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "\n",
    "    pos = np.array(positions)\n",
    "    rad = np.array(radii)\n",
    "    \n",
    "    # default to simple enumeration if no IDs provided\n",
    "    if particle_ids is None:\n",
    "        p_ids = np.arange(len(pos), dtype=np.int32)\n",
    "    else:\n",
    "        p_ids = np.array(particle_ids, dtype=np.int32)\n",
    "\n",
    "    # 1. Setup Points\n",
    "    points = vtk.vtkPoints()\n",
    "    if pos.shape[1] == 2:\n",
    "        pos_3d = np.column_stack((pos, np.zeros(pos.shape[0])))\n",
    "    else:\n",
    "        pos_3d = pos\n",
    "    points.SetData(numpy_support.numpy_to_vtk(pos_3d, deep=True))\n",
    "    \n",
    "    # 2. PolyData\n",
    "    polydata = vtk.vtkPolyData()\n",
    "    polydata.SetPoints(points)\n",
    "    \n",
    "    # 3. Add Data Arrays\n",
    "    point_data = polydata.GetPointData()\n",
    "    \n",
    "    # Diameter for scaling (Scale Factor 1.0)\n",
    "    diameters = rad * 2.0\n",
    "    scale_array = numpy_support.numpy_to_vtk(diameters, deep=True)\n",
    "    scale_array.SetName(\"Diameter\")\n",
    "    point_data.AddArray(scale_array)\n",
    "    \n",
    "    # Radius (optional, good to keep)\n",
    "    rad_array = numpy_support.numpy_to_vtk(rad, deep=True)\n",
    "    rad_array.SetName(\"Radius\")\n",
    "    point_data.AddArray(rad_array)\n",
    "    \n",
    "    # Particle ID for coloring\n",
    "    id_array = numpy_support.numpy_to_vtk(p_ids, deep=True)\n",
    "    id_array.SetName(\"ParticleID\")\n",
    "    point_data.AddArray(id_array)\n",
    "    \n",
    "    # Set active scalars (default coloring)\n",
    "    point_data.SetActiveScalars(\"ParticleID\")\n",
    "    \n",
    "    # 4. Write\n",
    "    writer = vtk.vtkXMLPolyDataWriter()\n",
    "    writer.SetFileName(filename)\n",
    "    writer.SetInputData(polydata)\n",
    "    writer.SetDataModeToBinary()\n",
    "    writer.Write()\n",
    "    print(f\"Wrote {len(pos)} particles to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f3195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fibonacci_sphere_coordinates(num_points, radius=1.0, asperity_radius=0.9):\n",
    "    \"\"\"\n",
    "    Generates x,y,z coordinates for points uniformly distributed on a sphere surface.\n",
    "    \"\"\"\n",
    "    # Create an array of indices from 0 to N-1\n",
    "    indices = np.arange(num_points, dtype=float) + 0.5\n",
    "    \n",
    "    # Golden angle in radians\n",
    "    phi = np.arccos(1 - 2 * indices / num_points)\n",
    "    theta = np.pi * (1 + 5**0.5) * indices\n",
    "\n",
    "    x = radius * np.cos(theta) * np.sin(phi)\n",
    "    y = radius * np.sin(theta) * np.sin(phi)\n",
    "    z = radius * np.cos(phi)\n",
    "\n",
    "    asperity_pos = np.column_stack((x, y, z))\n",
    "    rad = np.ones(num_points) * asperity_radius\n",
    "    asperity_pos = np.vstack((asperity_pos, np.zeros(3)))\n",
    "    rad = np.hstack((rad, np.ones(1) * radius))\n",
    "    return asperity_pos, rad, np.ones_like(rad)\n",
    "\n",
    "p_all = []\n",
    "rad_all = []\n",
    "p_ids_all = []\n",
    "\n",
    "for i, asperity_radius in enumerate([0.99, 0.9, 0.5, 0.3, 0.1, 0.01]):\n",
    "    N = 50\n",
    "    core_radius = 1.0 - asperity_radius\n",
    "    p, rad, p_ids = get_fibonacci_sphere_coordinates(N, core_radius, asperity_radius)\n",
    "    p[:, 0] += i * 2.0\n",
    "    p_all.append(p)\n",
    "    rad_all.append(rad)\n",
    "    p_ids_all.append(p_ids + i)\n",
    "\n",
    "p = np.concatenate(p_all)\n",
    "rad = np.concatenate(rad_all)\n",
    "p_ids = np.concatenate(p_ids_all)\n",
    "\n",
    "save_spheres_vtp(f\"asperities_3d.vtp\", p, rad, p_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebf5772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mu_eff(vertex_radius, outer_radius, num_vertices):\n",
    "    return 1 / np.sqrt(((2 * vertex_radius) / ((outer_radius - vertex_radius) * np.sin(np.pi / num_vertices))) ** 2 - 1)\n",
    "\n",
    "def generate_bidisperse_radii(total: int, count_ratio: float, size_ratio: float, small_size: float = 0.5):\n",
    "    \"\"\"\n",
    "    total: number of particles\n",
    "    count_ratio: proportion of particles that are the small size\n",
    "    size_ratio: large diameter in terms of the small diameter\n",
    "    small_size: diameter of the small particle\n",
    "    \"\"\"\n",
    "    if count_ratio > 1 or count_ratio < 0:\n",
    "        raise ValueError('count ratio out of bounds: 0 <= count_ratio <= 1')\n",
    "    if size_ratio < 0:\n",
    "        raise ValueError('size ratio out of bounds: 0 <= size_ratio')\n",
    "    n_small = int(total * count_ratio)\n",
    "    n_large = total - n_small\n",
    "    radii = np.ones(total).astype(DT_FLOAT)\n",
    "    radii[:n_small] = small_size\n",
    "    radii[n_small:] = small_size * size_ratio\n",
    "    return radii\n",
    "\n",
    "def generate_polydisperse_radii(total: int, std_dev: float, avg_size: float = 0.5, random_seed: int = 42):\n",
    "    \"\"\"\n",
    "    total: number of particles\n",
    "    std_dev: standard deviation of the gaussian\n",
    "    avg_size: size of the average particle\n",
    "    \"\"\"\n",
    "    print(\"TODO: verify that this is the right way to handle polydispersity\")\n",
    "    np.random.seed(random_seed)\n",
    "    return np.random.normal(size=total, loc=avg_size, scale=std_dev)\n",
    "\n",
    "def get_closest_vertex_radius_for_mu_eff(mu_eff, outer_radius, num_vertices):\n",
    "    # Calculate mathematically valid bounds\n",
    "    sin_term = np.sin(np.pi / num_vertices)\n",
    "    min_vertex_radius = outer_radius * sin_term / (2 + sin_term) + 1e-12\n",
    "    max_vertex_radius = outer_radius - 1e-12\n",
    "    \n",
    "    # Check if target mu_eff is achievable\n",
    "    max_mu_eff = calc_mu_eff(min_vertex_radius, outer_radius, num_vertices)\n",
    "    min_mu_eff = calc_mu_eff(max_vertex_radius, outer_radius, num_vertices)\n",
    "    \n",
    "    if mu_eff > max_mu_eff or mu_eff < min_mu_eff:\n",
    "        # Target mu_eff is outside achievable range\n",
    "        return np.nan\n",
    "    try:\n",
    "        # Use root finding since we want calc_mu_eff(vertex_radius) = mu_eff\n",
    "        def objective(vertex_radius):\n",
    "            return calc_mu_eff(vertex_radius, outer_radius, num_vertices) - mu_eff\n",
    "        \n",
    "        # Brent's method is robust for this monotonic function\n",
    "        result = brentq(objective, min_vertex_radius, max_vertex_radius, xtol=1e-12)\n",
    "        return result\n",
    "        \n",
    "    except (ValueError, RuntimeError, ZeroDivisionError):\n",
    "        # Fallback to bounded scalar minimization if root finding fails\n",
    "        def obj_squared(vertex_radius):\n",
    "            try:\n",
    "                return (calc_mu_eff(vertex_radius, outer_radius, num_vertices) - mu_eff) ** 2\n",
    "            except (ValueError, RuntimeError, ZeroDivisionError):\n",
    "                return np.inf\n",
    "        \n",
    "        result = minimize_scalar(obj_squared, bounds=(min_vertex_radius, max_vertex_radius), method='bounded')\n",
    "        return result.x if result.success else np.nan\n",
    "\n",
    "def get_closest_num_vertices_for_mu_eff_and_radii(mu_eff, outer_radius, vertex_radius, min_nv=1, max_nv=np.inf):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_closest_num_vertices_for_friction_and_segment_length(vertex_radius, outer_radius, target_segment_length, target_friction, target_num_vertices, vertex_count_offset=5, min_num_vertices=2):\n",
    "    ideal_num_vertices = target_num_vertices\n",
    "    min_cost = np.inf\n",
    "    for num_vertices in range(max(min_num_vertices, ideal_num_vertices - vertex_count_offset), ideal_num_vertices + vertex_count_offset):\n",
    "        if num_vertices <= min_num_vertices:\n",
    "            continue\n",
    "        vertex_angle = 2 * np.pi / num_vertices\n",
    "        inner_radius = outer_radius - vertex_radius\n",
    "        friction = calc_mu_eff(vertex_radius, outer_radius, num_vertices)\n",
    "        segment_length = inner_radius / vertex_radius * np.sin(vertex_angle / 2)\n",
    "\n",
    "        cost = abs(segment_length / target_segment_length - 1) + abs(friction / target_friction - 1)\n",
    "        if ~np.isnan(cost) and cost < min_cost:\n",
    "            ideal_num_vertices = num_vertices\n",
    "            min_cost = cost\n",
    "    return ideal_num_vertices\n",
    "\n",
    "def get_bumpy_dists(num_vertices, outer_radius, vertex_radius):\n",
    "    sigma = outer_radius * 2\n",
    "    sigma_v = vertex_radius * 2\n",
    "    n_v = num_vertices\n",
    "    sigma_p_i = sigma - sigma_v\n",
    "    # the closest center-to-center distance between two particles of the same species at a symmetric contact\n",
    "    d_0 = (np.cos(np.pi / n_v) / 2 + 1 / 2 + np.sqrt((sigma_v / sigma_p_i) ** 2 - (np.sin(np.pi / n_v) / 2) ** 2)) * sigma_p_i\n",
    "    # the absolute closest center-to-center distance between two particles of the same species\n",
    "    d_min = (np.sqrt(np.cos(np.pi / n_v) ** 2 + (sigma_v / sigma_p_i) ** 2 + np.cos(np.pi / n_v) * np.sqrt(4 * (sigma_v / sigma_p_i) ** 2 - np.sin(np.pi / n_v) ** 2))) * sigma_p_i\n",
    "    return d_0, d_min"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxdem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
